{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifty-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'F:/Projects/PAE_PlaceCell/ProcessedData/'\n",
    "spike_path = 'F:/Projects/PAE_PlaceCell/analysis/spikes/'\n",
    "swr_df = pd.read_csv('F:/Projects/PAE_PlaceCell/analysis/swr_data/post_processed/swr_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_affiliation(df):\n",
    "    control=('RH13','RH14','LS21','LS23','LE2821','LE2823','LEM3116','LEM3120','LEM3216')\n",
    "    pae=('RH11','RH16','LS17','LS19','LE2813','LEM3124','LEM3206','LEM3246')\n",
    "\n",
    "    df['group'] = np.ones_like(df.session)\n",
    "\n",
    "    regstr = '|'.join(control)\n",
    "    idx = df['session'].str.upper().str.contains(regstr)    \n",
    "    df.group[idx] = 'control'\n",
    "\n",
    "    regstr = '|'.join(pae)\n",
    "    idx = df['session'].str.upper().str.contains(regstr)    \n",
    "    df.group[idx] = 'pae'\n",
    "    return df\n",
    "\n",
    "def add_epoch_type(df,data_path):\n",
    "    dicts = {}\n",
    "    for session in df.session:\n",
    "        f = h5py.File(data_path+session+'.mat','r')\n",
    "        ex_ep = []\n",
    "        for i in range(f['events'].shape[0]):\n",
    "            ex_ep.append(f['events'][i])\n",
    "        dicts[session] = ex_ep\n",
    "\n",
    "    ep_type = ['pedestal_1','track','pedestal_2','cylinder_1','pedestal_3','cylinder_2','pedestal_4']\n",
    "    df['ep_type'] = np.ones_like(df.session)\n",
    "    # session_df=pd.DataFrame()\n",
    "    for session in np.unique(df.session):\n",
    "        # stack epoch times\n",
    "        b = np.hstack(dicts[session])\n",
    "\n",
    "        # add 0 to start to indicate the start of the recording session\n",
    "        b = np.insert(b,0,0)\n",
    "\n",
    "        # add the ts of the last ripple of the session to indicate end of session\n",
    "        b = list(b)\n",
    "        last_rip = max(df.ts[df.session == session])\n",
    "        if b[-1] < last_rip:\n",
    "            b.append(last_rip)\n",
    "\n",
    "        # loop through each epoch and label each ripple\n",
    "        for ep in range(len(b)-1):\n",
    "            idx = (df.session == session) & (df.ts >= b[ep]) & (df.ts <= b[ep+1])\n",
    "            df.loc[idx,'ep_type'] = ep_type[ep]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_types = []\n",
    "epoch_durations = []\n",
    "sessions = []\n",
    "for session in pd.unique(swr_df.session):\n",
    "    print(session)\n",
    "    # load spikes to get max and min of session\n",
    "    spikes = np.load(os.path.join(spike_path,session)+'.npy', allow_pickle=True)\n",
    "    spikes_ = list(itertools.chain(*spikes))\n",
    "    # generate time stamps with dt of .5 seconds\n",
    "    ts = np.arange(min(spikes_), max(spikes_),.5)\n",
    "    # make df to feed into add_epoch_type\n",
    "    df_test = pd.DataFrame()\n",
    "    df_test['session'] = np.full(ts.shape[0], session)\n",
    "    df_test['ts'] = ts\n",
    "    df_test = add_epoch_type(df_test,data_path)\n",
    "    # loop through each ep_type to collect ep type and epoch durations\n",
    "    for ep_type in pd.unique(df_test.ep_type):\n",
    "        sessions.append(session)\n",
    "        ep_types.append(ep_type)\n",
    "        epoch_durations.append(df_test.ts[df_test.ep_type == ep_type].max() - df_test.ts[df_test.ep_type == ep_type].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_df = pd.DataFrame()\n",
    "\n",
    "epoch_df['session'] = sessions\n",
    "epoch_df['ep_type'] = ep_types\n",
    "epoch_df['epoch_duration'] = epoch_durations\n",
    "\n",
    "epoch_df = add_group_affiliation(epoch_df)    \n",
    "epoch_df\n",
    "\n",
    "epoch_df.to_csv('F:/Projects/PAE_PlaceCell/analysis/epoch_df.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
